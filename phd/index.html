<!DOCTYPE html>
<html>
<meta charset="UTF-8">
<head>
	<base href="http://spewil.github.io/">
    <link rel="stylesheet" href="/css/full.css">
    <script src="https://hypothes.is/embed.js" async></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</head>
<body>
<div class="wrap">
<div class="main">
<h2 id="where-are-you">Where are you?</h2>
<p>This is an experiment in creating an open kind of thesis. I would like to work together using the nonprofit <a href="https://web.hypothes.is/" target="_blank">Hypothes.is</a> toolkit to annotate this living document, for which we’ll track changes using <a href="www.github.com/spewil/">git</a>. In less than two years, this page will represent the culminated collective effort of a few people to better understand the organizing principles of human motor learning.</p>
<p>To start adding comments to this page, just highlight some text, click <code>annotate</code> and start typing. Note that you will have to a <a href="https://web.hypothes.is/" target="_blank">Hypothes.is</a> account, but it only takes a second.</p>
<h2 id="what-am-i-doing">What am I doing?</h2>
<p>I’m working on my PhD at the Sainsbury Wellcome Centre for Neural Circuits and Behavior in London. I’m setting up a family of experiments that I hope will test hypotheses about the organizing principles of sensorimotor control and learning. I’m setting up a task where I record from participants’ muscles in their arms and hands using <code>electromyography</code>. Subjects’ arms and hands are fixed in a brace, but as they send signals from their brain down to their spinal cords and ultimately to their muscles, my electrodes will sense this change in electrical potential and relay this change to the computer, which will reflect these changes through visuals shown on a screen. The object of the game is for the participant to learn which muscle activations correspond to which changes in the visual scene. You can think about this as a video game you’re playing directly with your muscles.</p>
<h2 id="phd-timeline">PhD Timeline</h2>
<ul>
<li>Year 1 (October 2018 - October 2019)
<ul>
<li>coursework (October 2018 - March 2019)</li>
<li><a href="/phd/rotations/mouse_ball.html" target="_blank">mouse wheel task in Mrsic-Flogel Lab</a> (Jan 2019 - March 2019)</li>
<li><a href="/phd/rotations/ctrl-labs.html" target="_blank">ctrl-labs rotation in NYC</a> (April 2019 - June 2019)</li>
<li><a href="https://www.sainsburywellcome.org/web/groups/murray-lab" target="_blank">MurrayLab rotation</a> (July 2019 - August 2019)</li>
<li><a href="https://github.com/swcphd/greyboxes" target="_blank">Organize SWC PhD Bootcamp</a> (September 2019)</li>
</ul></li>
<li>Year 2 (October 2019 - October 2020)
<ul>
<li>list of thesis committee members</li>
<li>project proposal with literature search</li>
<li>data club presentation / 6-month review (May)</li>
<li>SfN poster introducing setup, concept</li>
<li>final draft of project proposal</li>
<li>introduction and background chapters</li>
<li>upgrade / 2nd year review (October)</li>
<li>preliminary task data</li>
</ul></li>
<li>Year 3 (October 2020 - October 2021)
<ul>
<li>finer-grained experiments, supporting experiments</li>
<li>theory chapter</li>
<li>modeling chapter</li>
</ul></li>
<li>Year 4 (October 2020 - October 2021)</li>
</ul>
<h1 id="purpose">Purpose</h1>
<blockquote>
<p>The processes by which biological control solutions spanning large and continuous state spaces are constructed remain relatively unexplored. Future investigations may need to embed rich dynamical interactions between object dynamics and task goals in novel and complex movements.<span class="citation" data-cites="McNamee2019"><sup>1</sup></span></p>
</blockquote>
<p>We know surprisingly little about how this process unfolds in the brain. So little, in fact, that we haven’t quite figured out what the brain is actually doing. We know that it is involved in these muscle contractions, but what sort of strategy do you use to explore this space of possible mappings between what you experience when you move and what you expect to see and feel as a result? This is the question I hope to make headway on.</p>
<p>To do this, I’ll use the literature of reinforcement learning and optimal control theory to guide my theoretical understanding of what is happening when a subject begins to experience learning in this novel situation. I will model hypotheses of this learning process and compare these models to the large amounts of data my experimental setup will produce as we track learning of subjects over many sessions.</p>
<h1 id="background">Background</h1>
<h2 id="what-are-muscles">What are muscles?</h2>
<p>Muscles are collections of fibers that contract when chemical gradients are produced at the neuromuscular junction by action potentials emanating from neurons in the ventral horn of the spinal cord.</p>
<h2 id="what-is-electromyography">What is electromyography?</h2>
<p>Electromyography is the detection of changes in chemical potential using electrodes. In my setup, we use a total 64 monopolar surface electrodes and monopolar needle electrodes to record chemical potentials from muscles in the forearm and hand.</p>
<h2 id="what-is-our-understanding-of-how-humans-control-their-bodies">What is our understanding of how humans control their bodies?</h2>
<h1 id="theory">Theory</h1>
<h2 id="task-formalization">Task Formalization</h2>
<p>In this task, the subject’s first goal is to interact through an unknown visuomotor mapping and internalize this model. The second problem is to use this model to solve a control problem.</p>
<ol type="1">
<li>System Identification – learning a transition function <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>y</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mi>t</mi></msub><mo>,</mo><msub><mi>u</mi><mi>t</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">p(y_t|x_t, u_t)</annotation></semantics></math>
<ul>
<li>How do you learn the unknown observation model from data?</li>
</ul></li>
<li>Policy Optimization
<ul>
<li>Once dynamics are learned (or at least stable?), how do we form a policy that is generalizable to new tasks under these dynamics?</li>
<li>This is the control problem.</li>
</ul></li>
</ol>
<p>It’s safe to assume that these processes are happening in parallel. Because we have complete and arbitrary control over the observation mapping, we can ask the subject to interact through a dynamic that is intuitive (informative prior) or unintuitive (uninformative or inhibitive prior). Each scenario, we hypothesize, will elicit different strategies for learning and control.</p>
<p>The unknown mapping <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math> from muscle to task space looks like the observation matrix <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>H</mi><annotation encoding="application/x-tex">H</annotation></semantics></math> in the LQG problem:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right"><msub><mi>y</mi><mi>t</mi></msub></mtd><mtd columnalign="left"><mo>=</mo><mi>H</mi><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><msub><mi>v</mi><mi>t</mi></msub><mspace width="0.167em"></mspace><mspace width="0.167em"></mspace><mspace width="0.167em"></mspace><mo stretchy="false" form="prefix">(</mo><mstyle mathvariant="normal"><mi>L</mi><mi>Q</mi><mi>G</mi></mstyle><mo stretchy="false" form="postfix">)</mo></mtd></mtr><mtr><mtd columnalign="right"><msub><mi>y</mi><mi>t</mi></msub></mtd><mtd columnalign="left"><mo>=</mo><mi>M</mi><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><msub><mi>v</mi><mi>t</mi></msub><mi>.</mi><mspace width="0.167em"></mspace><mspace width="0.167em"></mspace><mspace width="0.167em"></mspace><mo stretchy="false" form="prefix">(</mo><mstyle mathvariant="normal"><mi>e</mi><mi>x</mi><mi>p</mi><mi>e</mi><mi>r</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>n</mi><mi>t</mi></mstyle><mo stretchy="false" form="postfix">)</mo></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{align*}
y_t &amp;= Hx_t + v_t\,\,\,(\mathrm{LQG}) \\
y_t &amp;= Mx_t + v_t. \,\,\,(\mathrm{experiment})
\end{align*}
</annotation></semantics></math></p>
<p>The state dynamics in the task are of the form:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right"><msub><mi>x</mi><mi>t</mi></msub></mtd><mtd columnalign="left"><mo>=</mo><mi>A</mi><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>B</mi><msub><mi>u</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>w</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mspace width="0.167em"></mspace><mspace width="0.167em"></mspace><mspace width="0.167em"></mspace><mo stretchy="false" form="prefix">(</mo><mstyle mathvariant="normal"><mi>L</mi><mi>Q</mi><mi>G</mi></mstyle><mo stretchy="false" form="postfix">)</mo></mtd></mtr><mtr><mtd columnalign="right"><msub><mi>x</mi><mi>t</mi></msub></mtd><mtd columnalign="left"><mo>=</mo><mi>D</mi><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>I</mi><msub><mi>u</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>w</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mspace width="0.167em"></mspace><mspace width="0.167em"></mspace><mspace width="0.167em"></mspace><mo stretchy="false" form="prefix">(</mo><mstyle mathvariant="normal"><mi>e</mi><mi>x</mi><mi>p</mi><mi>e</mi><mi>r</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>n</mi><mi>t</mi></mstyle><mo stretchy="false" form="postfix">)</mo></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{align*}
x_{t} &amp;= Ax_{t-1} + Bu_{t-1} + w_{t-1} \,\,\,(\mathrm{LQG}) \\
x_t &amp;= Dx_{t-1} + Iu_{t-1} + w_{t-1} \,\,\,(\mathrm{experiment})
\end{align*}
</annotation></semantics></math></p>
<p>where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>D</mi><annotation encoding="application/x-tex">D</annotation></semantics></math> is a diagonal decay matrix of with terms <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mstyle mathvariant="normal"><mi>e</mi></mstyle><mrow><mo>−</mo><mi>λ</mi></mrow></msup><annotation encoding="application/x-tex">\mathrm{e}^{-\lambda}</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>I</mi><annotation encoding="application/x-tex">I</annotation></semantics></math> is the identity. The subject produces muscle contractions which add to the current latent (unobserved) state. In the absence of control signals, the state decays back to <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>0</mn><annotation encoding="application/x-tex">0</annotation></semantics></math> in line with the physics of your arm returning to a passive state in the absence of muscle contractions. The terms <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>w</mi><annotation encoding="application/x-tex">w</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>v</mi><annotation encoding="application/x-tex">v</annotation></semantics></math> are gaussian noise vectors with distributions <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="script"><mi>𝒩</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mn>0</mn><mo>,</mo><mi>Q</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{N}(0,Q)</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="script"><mi>𝒩</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mn>0</mn><mo>,</mo><mi>R</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{N}(0,R)</annotation></semantics></math>. If we combine the transition and observation models:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right"><msub><mi>y</mi><mi>t</mi></msub></mtd><mtd columnalign="left"><mo>=</mo><mi>M</mi><mi>D</mi><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>M</mi><msub><mi>u</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>M</mi><msub><mi>w</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>v</mi><mi>t</mi></msub></mtd></mtr><mtr><mtd columnalign="right"></mtd><mtd columnalign="left"><mo>=</mo><msup><mi>A</mi><mi>′</mi></msup><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msup><mi>B</mi><mi>′</mi></msup><msub><mi>u</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>M</mi><msub><mi>w</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>v</mi><mi>t</mi></msub><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{align*}
y_t &amp;= MDx_{t-1} + Mu_{t-1} + Mw_{t-1} + v_t \\
&amp;= A^\prime x_{t-1} + B^\prime u_{t-1} + Mw_{t-1} + v_t.
\end{align*}
</annotation></semantics></math></p>
<p>We can think of this as the combined system identification problem where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><mi>′</mi></msup><mo>=</mo><mi>M</mi><mi>D</mi></mrow><annotation encoding="application/x-tex">A^\prime=MD</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>B</mi><mi>′</mi></msup><mo>=</mo><mi>M</mi></mrow><annotation encoding="application/x-tex">B^\prime=M</annotation></semantics></math> are unknown and must be estimated. The noise covariances of this altered system are now non-trivial, however. We could also assume that the transition dynamic <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>D</mi><annotation encoding="application/x-tex">D</annotation></semantics></math> is known and that the identification problem is learning the mapping <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math> only. This might not be a poor assumption since the exponential decay is meant to serve as an intuitive passive dynamic.</p>
<p>In each trial of the task, a subject will have some internal representation of the observation dynamic <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math> which may or may not be accurate. In order to make accurate predictions, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math> must be estimated.</p>
<p>Learning linear dynamical systems from data is a hot topic of research, most of which seems to focus on learning in the context of complete state observation (<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>=</mo><mi>I</mi></mrow><annotation encoding="application/x-tex">M=I</annotation></semantics></math>, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><mi>x</mi></mrow><annotation encoding="application/x-tex">y=x</annotation></semantics></math>). Algorithms to determine parameters of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math> are proposed (see Dean, Recht 2018).</p>
<p>From LQG theory we know that the control law is a linear function of the state:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right"><msub><mi>u</mi><mi>t</mi></msub><mo>=</mo><mo>−</mo><msub><mi>L</mi><mi>t</mi></msub><msub><mi>x</mi><mi>t</mi></msub></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{align*}
u_t = -L_tx_t
\end{align*}
</annotation></semantics></math></p>
<p>and thus our combined system dynamic is:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right"><msub><mi>y</mi><mi>t</mi></msub></mtd><mtd columnalign="left"><mo>=</mo><mi>M</mi><mo stretchy="false" form="prefix">(</mo><mi>D</mi><mo>−</mo><msub><mi>L</mi><mi>t</mi></msub><mo stretchy="false" form="postfix">)</mo><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>M</mi><msub><mi>w</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>v</mi><mi>t</mi></msub><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{align*}
y_t &amp;= M(D-L_t)x_{t-1} + Mw_{t-1} + v_t.
\end{align*}
</annotation></semantics></math></p>
<p>The noise covariance due to the observation Q is unchanged, but the new noise covariance for the latent process is now <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>R</mi><msup><mi>M</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">MRM^T</annotation></semantics></math>. This may make things difficult.</p>
<h4 id="questions">Questions</h4>
<ul>
<li>How does the observation mapping relate to the latent state covariance? The task state covariance?</li>
<li>How do we formalize this into a probabilistic graphical model? Why would we?
<ul>
<li>Would this make it easier to reason about what the goals are?</li>
<li>Would learning <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math> become an inference problem?</li>
<li>Would solving the control problem become an inference problem…?</li>
</ul></li>
<li>What noise assumptions can we make? Can we not make?
<ul>
<li>How can we incorporate signal-dependent noise?</li>
</ul></li>
</ul>
<h3 id="model-based-reinforcement-learning">Model-based Reinforcement Learning</h3>
<p>Since we only have an approximate model of the system dynamic, we could simply work towards an optimal policy directly using gradient derivative-free optimization methods in a model-free approach. Since we have good evidence that humans leverage internal models to make decisions (at least in a motor problem domain), we need to define an algorithm which uses past observations and controls to update our approximation for the system dynamic. Here is a very general algorithm:</p>
<ol start="0" type="1">
<li>Define a base policy/controller and base system model (<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>L</mi><mn>0</mn></msub><annotation encoding="application/x-tex">L_0</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>M</mi><mo accent="true">̂</mo></mover><mn>0</mn></msub><annotation encoding="application/x-tex">\hat{M}_0</annotation></semantics></math>)</li>
<li>Collect samples (by interacting with the true environment <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>M</mi><mrow><mi>t</mi><mi>r</mi><mi>u</mi><mi>e</mi></mrow></msub><annotation encoding="application/x-tex">M_{true}</annotation></semantics></math>) using the current policy/controller (collect <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>t</mi></msub><mo>,</mo><msub><mi>u</mi><mi>t</mi></msub><mo>,</mo><msub><mi>y</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">y_t,u_t,y_{t+1}</annotation></semantics></math> triples using <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>L</mi><mi>i</mi></msub><annotation encoding="application/x-tex">L_i</annotation></semantics></math> for <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>∈</mo><mo stretchy="false" form="prefix">{</mo><mn>0</mn><mi>…</mi><mi>N</mi><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">i \in \{0\dots N\}</annotation></semantics></math></li>
<li>Use sample(s) / trajectories to update current system dynamical model <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>M</mi><mo accent="true">̂</mo></mover><mi>i</mi></msub><annotation encoding="application/x-tex">\hat{M}_i</annotation></semantics></math></li>
<li>Update current policy/controller <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>L</mi><mi>i</mi></msub><annotation encoding="application/x-tex">L_i</annotation></semantics></math> (using the system dynamics or using a direct policy method)</li>
</ol>
<p>If the true system dynamics were known, we could solve the Algebraic Riccati Equation with a backwards pass, and compute our controls in a forward pass. This general algorithm structure highlights how the (unknown) system identification and controller design are intertwined: identifying a system appropriately must rely on sampling and fitting regions of the state space pertinent to adequate control in terms of cost (Ross ICML 2012). Otherwise, our approximation to the true system dynamic will only produce a valid controller in regions we have previously explored. The question is how we can effectively (sample and time efficiently) utilize new state transitions we encounter either online as feedback or between trials to update our model and policy. That is, the number of trials and/or trajectories to use before updating either the system model and/or policy is an important parameter.</p>
<p>In the LQG setting, this might be called “adaptive LQG”.</p>
<h4 id="questions-1">Questions</h4>
<ul>
<li>how does a subject sample the state space as to efficiently learn? do they sample optimally? how does controller/policy optimization proceed based on system identification?</li>
<li>how does a human subject use error information from each trial and feedback from each time step to update their model and/or policy?
<ul>
<li>how does a subject balance policy updates with model updates?</li>
</ul></li>
<li>On what scale (trials, timesteps) is the model altered? the policy?
<ul>
<li>Replanning at every timestep is a model predictive control algorithm</li>
<li>What prediction can we make for ID/learning every trial?</li>
</ul></li>
<li>how does a subject avoid “distribution mismatch” between their base policy and their optimal policy? How do they efficiently explore and use this new data to update their internal model?
<ul>
<li>what exploration strategy does a subject use to avoid mismatch?</li>
<li>what</li>
</ul></li>
<li>What is a subject’s baseline/prior model? <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>t</mi></msub><mo>=</mo><msub><mover><mi>f</mi><mo accent="true">̂</mo></mover><mn>0</mn></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo>,</mo><msub><mi>u</mi><mi>t</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">y_{t} = \hat{f}_0(x_t,u_t)</annotation></semantics></math> or <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>t</mi></msub><mo>∝</mo><msub><mi>p</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>y</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mi>t</mi></msub><mo>,</mo><msub><mi>u</mi><mi>t</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">y_{t} \propto p_0(y_t|x_{t},u_t)</annotation></semantics></math></li>
<li>What is the base policy / prior policy? <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mi>t</mi></msub><mo>=</mo><msub><mi>π</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">(</mo><msub><mover><mi>x</mi><mo accent="true">̂</mo></mover><mi>t</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">u_t = \pi_0(\hat{x}_t)</annotation></semantics></math></li>
<li>How do we think about learning a distribution over trajectories in control law space, or perhaps equivalently, in covariance/precision space?</li>
<li>We might hypothesize that a subject will act as randomly as possible while minimizing cost, a maximum entropy solution that converges to an optimal controller? <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="script"><mi>ℋ</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mi>p</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>u</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{H}(p(u_t|x_t))</annotation></semantics></math></li>
<li>How does a subject penalize changes to their controllers? Do they follow a KL-divergence type of measurement when improving their policy?</li>
</ul>
<h2 id="modeling-error-based-learning-with-linear-dynamical-systems">Modeling Error-based Learning with Linear Dynamical Systems</h2>
<p><em>Modeling Sensorimotor Learning with Linear Dynamical Systems</em> by Cheng and Sabes, 2006. The goal is to model trial-by-trial learning by fitting data to a linear dynamical system model. Here we’ll call <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>F</mi><mi>t</mi></msub><annotation encoding="application/x-tex">F_t</annotation></semantics></math> the <strong>sensorimotor mapping</strong> transforming inputs <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>w</mi><mi>t</mi></msub><annotation encoding="application/x-tex">w_t</annotation></semantics></math> to <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mi>t</mi></msub><annotation encoding="application/x-tex">y_t</annotation></semantics></math> outputs per trial:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>t</mi></msub><mo>=</mo><msub><mi>F</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>w</mi><mi>t</mi></msub><mo>,</mo><msub><mi>γ</mi><mi>t</mi></msub><mo stretchy="false" form="postfix">)</mo><mi>.</mi></mrow><annotation encoding="application/x-tex">
y_t = F_t(w_t, \gamma_t).
</annotation></semantics></math></p>
<p>This can be thought of as a mapping from inputs within a single trial to, for example, endpoint error. Noise is captured by the <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>γ</mi><mi>t</mi></msub><annotation encoding="application/x-tex">\gamma_t</annotation></semantics></math>. The trajectory in <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>F</mi><annotation encoding="application/x-tex">F</annotation></semantics></math> space attempts to capture the process of learning. The learning rule <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>L</mi><mi>t</mi></msub><annotation encoding="application/x-tex">L_t</annotation></semantics></math> can be written</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>L</mi><mi>t</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mrow><mo stretchy="true" form="prefix">{</mo><msub><mi>F</mi><mi>τ</mi></msub><mo stretchy="true" form="postfix">}</mo></mrow><mrow><mi>τ</mi><mo>=</mo><mn>1</mn></mrow><mi>t</mi></msubsup><mo>,</mo><msub><mi>u</mi><mi>t</mi></msub><mo>,</mo><msub><mi>η</mi><mi>t</mi></msub><mo>,</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">F_{t+1} = L_t\left(\left\{F_\tau\right\}_{\tau=1}^{t}, u_t, \eta_t, t\right)</annotation></semantics></math></p>
<p>where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msubsup><mrow><mo stretchy="true" form="prefix">{</mo><msub><mi>F</mi><mi>τ</mi></msub><mo stretchy="true" form="postfix">}</mo></mrow><mrow><mi>τ</mi><mo>=</mo><mn>1</mn></mrow><mi>t</mi></msubsup><annotation encoding="application/x-tex">\left\{F_\tau\right\}_{\tau=1}^{t}</annotation></semantics></math> is the history of the mapping, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>u</mi><mi>t</mi></msub><annotation encoding="application/x-tex">u_t</annotation></semantics></math> is the history of the total inputs to learning which could encompass <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>w</mi><annotation encoding="application/x-tex">w</annotation></semantics></math>, and exogenous inputs <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>r</mi><annotation encoding="application/x-tex">r</annotation></semantics></math>. Noise in the learning is captured by <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>η</mi><annotation encoding="application/x-tex">\eta</annotation></semantics></math>.</p>
<p>We can approximate this learning problem using linear equations by assuming that <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mi>t</mi></msub><mo>=</mo><mi>L</mi><mspace width="0.222em"></mspace><mo>∀</mo><mspace width="0.222em"></mspace><mi>t</mi></mrow><annotation encoding="application/x-tex">L_t=L \ \forall \ t</annotation></semantics></math> is stationary, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>F</mi><mi>t</mi></msub><annotation encoding="application/x-tex">F_t</annotation></semantics></math> is parameterized by <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub><mo>∈</mo><msup><mstyle mathvariant="double-struck"><mi>ℝ</mi></mstyle><mi>y</mi></msup></mrow><annotation encoding="application/x-tex">x_t\in\mathbb{R}^y</annotation></semantics></math>. Thus,</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right"><msub><mi>y</mi><mi>t</mi></msub></mtd><mtd columnalign="left"><mo>=</mo><mi>F</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo>,</mo><msub><mi>w</mi><mi>t</mi></msub><mo>,</mo><msub><mi>γ</mi><mi>t</mi></msub><mo stretchy="false" form="postfix">)</mo></mtd></mtr><mtr><mtd columnalign="right"><msub><mi>x</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mtd><mtd columnalign="left"><mo>=</mo><mi>L</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo>,</mo><msub><mi>u</mi><mi>t</mi></msub><mo>,</mo><msub><mi>η</mi><mi>t</mi></msub><mo stretchy="false" form="postfix">)</mo><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
y_t &amp;= F(x_t, w_t, \gamma_t) \\
x_{t+1} &amp;= L(x_t, u_t, \eta_t).
\end{aligned}
</annotation></semantics></math></p>
<p>The trial-to-trial input-output mapping <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>F</mi><annotation encoding="application/x-tex">F</annotation></semantics></math> is now fixed, and is transformed by trial through its parameters <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>t</mi></msub><annotation encoding="application/x-tex">x_t</annotation></semantics></math> by <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>L</mi><annotation encoding="application/x-tex">L</annotation></semantics></math>. Note that both mappings are Markovian and there are two input vectors, one for within-trial and one between-trial. These can include overlap. We can now linearize these mappings around an equilibrium point:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right"><msub><mi>x</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>−</mo><msub><mi>x</mi><mi>e</mi></msub></mtd><mtd columnalign="left"><mo>=</mo><mi>A</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo>−</mo><msub><mi>x</mi><mi>e</mi></msub><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mi>B</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>u</mi><mi>t</mi></msub><mo>−</mo><msub><mi>u</mi><mi>e</mi></msub><mo stretchy="false" form="postfix">)</mo><mo>+</mo><msub><mi>η</mi><mi>t</mi></msub></mtd></mtr><mtr><mtd columnalign="right"><msub><mi>y</mi><mi>t</mi></msub><mo>−</mo><msub><mi>m</mi><mi>e</mi></msub></mtd><mtd columnalign="left"><mo>=</mo><mi>C</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo>−</mo><msub><mi>x</mi><mi>e</mi></msub><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mi>D</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>w</mi><mi>t</mi></msub><mo>−</mo><msub><mi>w</mi><mi>e</mi></msub><mo stretchy="false" form="postfix">)</mo><mo>+</mo><msub><mi>γ</mi><mi>t</mi></msub></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
x_{t+1} - x_e &amp;= A(x_t-x_e) + B(u_t-u_e) + \eta_t \\
y_t - m_e &amp;= C(x_t-x_e) + D(w_t-w_e) + \gamma_t
\end{aligned}
</annotation></semantics></math></p>
<p>As shown by Cheng and Sabes, we can bundle the equilibrium terms into a bias term and drop this term if we mean-subtract our data (<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub><mo>,</mo><msub><mi>y</mi><mi>t</mi></msub><mo>,</mo><msub><mi>u</mi><mi>t</mi></msub><mo>,</mo><msub><mi>w</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">x_t, y_t, u_t, w_t</annotation></semantics></math>) when it’s time to fit. This gives us a simple linear dynamical system:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right"><msub><mi>x</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mtd><mtd columnalign="left"><mo>=</mo><mi>A</mi><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><mi>B</mi><msub><mi>u</mi><mi>t</mi></msub><mo>+</mo><msub><mi>η</mi><mi>t</mi></msub></mtd></mtr><mtr><mtd columnalign="right"><msub><mi>y</mi><mi>t</mi></msub></mtd><mtd columnalign="left"><mo>=</mo><mi>C</mi><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><mi>D</mi><msub><mi>w</mi><mi>t</mi></msub><mo>+</mo><msub><mi>γ</mi><mi>t</mi></msub><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
x_{t+1} &amp;= Ax_t + Bu_t + \eta_t \\
y_t &amp;= Cx_t + Dw_t + \gamma_t.
\end{aligned}
</annotation></semantics></math></p>
<p>The first equation governs the evolution of parameters of the within-trial input-output mapping, while the second equation governs the trial output given the current within-trial mapping parameters <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>t</mi></msub><annotation encoding="application/x-tex">x_t</annotation></semantics></math> and learning inputs <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>w</mi><mi>t</mi></msub><annotation encoding="application/x-tex">w_t</annotation></semantics></math>. The parameters <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>t</mi></msub><annotation encoding="application/x-tex">x_t</annotation></semantics></math> are hidden variables that are only observed through the output <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mi>t</mi></msub><annotation encoding="application/x-tex">y_t</annotation></semantics></math>. The noise terms <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>η</mi><mi>t</mi></msub><annotation encoding="application/x-tex">\eta_t</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>γ</mi><mi>t</mi></msub><annotation encoding="application/x-tex">\gamma_t</annotation></semantics></math> are normally distributed with covariances <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>R</mi><annotation encoding="application/x-tex">R</annotation></semantics></math>, respectively. <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math> governs the passive trajectory of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>t</mi></msub><annotation encoding="application/x-tex">x_t</annotation></semantics></math>. If <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>=</mo><mstyle mathvariant="double-struck"><mi>𝕀</mi></mstyle></mrow><annotation encoding="application/x-tex">A=\mathbb{I}</annotation></semantics></math>, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>t</mi></msub><annotation encoding="application/x-tex">x_t</annotation></semantics></math> does not decay passively.</p>
<p>There is a general form for this model which separates endogenous input <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mi>t</mi></msub><annotation encoding="application/x-tex">y_t</annotation></semantics></math> from exogenous input <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>r</mi><mi>t</mi></msub><annotation encoding="application/x-tex">r_t</annotation></semantics></math></p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right"><msub><mi>x</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mtd><mtd columnalign="left"><mo>=</mo><mi>A</mi><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><mo stretchy="false" form="prefix">[</mo><mi>G</mi><mspace width="0.222em"></mspace><mi>H</mi><mo stretchy="false" form="postfix">]</mo><mo stretchy="false" form="prefix">[</mo><msub><mi>r</mi><mi>t</mi></msub><mspace width="0.222em"></mspace><msub><mi>y</mi><mi>t</mi></msub><msup><mo stretchy="false" form="postfix">]</mo><mi>T</mi></msup><mo>+</mo><msub><mi>η</mi><mi>t</mi></msub></mtd></mtr><mtr><mtd columnalign="right"><msub><mi>y</mi><mi>t</mi></msub></mtd><mtd columnalign="left"><mo>=</mo><mi>C</mi><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><mi>D</mi><msub><mi>w</mi><mi>t</mi></msub><mo>+</mo><msub><mi>γ</mi><mi>t</mi></msub></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
x_{t+1} &amp;= Ax_t + [G \ H][r_t \ y_t]^T + \eta_t \\
y_t &amp;= Cx_t + Dw_t + \gamma_t
\end{aligned}
</annotation></semantics></math></p>
<p>where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>H</mi><annotation encoding="application/x-tex">H</annotation></semantics></math> governs biases in directions of the outputs. A unbiased output is isotropic. To add explicit stationary bias we write</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right"><msub><mi>x</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mtd><mtd columnalign="left"><mo>=</mo><mi>A</mi><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><mi>G</mi><msub><mi>r</mi><mi>t</mi></msub><mo>+</mo><mi>H</mi><msub><mi>y</mi><mi>t</mi></msub><mo>−</mo><mi>H</mi><msub><mi>b</mi><mi>x</mi></msub><mo>+</mo><msub><mi>η</mi><mi>t</mi></msub><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
x_{t+1} &amp;= Ax_t + Gr_t + Hy_t - Hb_x + \eta_t.
\end{aligned}
</annotation></semantics></math></p>
<h3 id="example-models">Example Models</h3>
<h4 id="feedback-error-learning">Feedback Error Learning</h4>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><mn>1</mn><mo>=</mo><mi>A</mi><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><mo stretchy="false" form="prefix">[</mo><mi>H</mi><mspace width="0.222em"></mspace><mi>H</mi><mo stretchy="false" form="postfix">]</mo><mo stretchy="false" form="prefix">[</mo><mo>−</mo><msubsup><mi>y</mi><mi>t</mi><mo>*</mo></msubsup><mspace width="0.222em"></mspace><msub><mi>y</mi><mi>t</mi></msub><msup><mo stretchy="false" form="postfix">]</mo><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">x_t+1 = Ax_t + [H\ H][-y_t^*\ y_t]^T</annotation></semantics></math></p>
<p>The second term is simply the difference between the output <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mi>t</mi></msub><annotation encoding="application/x-tex">y_t</annotation></semantics></math> and the desired output <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msubsup><mi>y</mi><mi>t</mi><mo>*</mo></msubsup><annotation encoding="application/x-tex">y_t^*</annotation></semantics></math>.</p>
<h4 id="prediction-error-learning">Prediction Error Learning</h4>
<p>Let <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mi>t</mi></msub><mo>=</mo><msub><mi>y</mi><mi>t</mi></msub><mo>−</mo><msub><mover><mi>y</mi><mo accent="true">̂</mo></mover><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">u_t = y_t - \hat{y}_t</annotation></semantics></math> where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>y</mi><mo accent="true">̂</mo></mover><mi>t</mi></msub><annotation encoding="application/x-tex">\hat{y}_t</annotation></semantics></math>, the difference between the output and the predicted output such that</p>
<p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>y</mi><mo accent="true">̂</mo></mover><mi>t</mi></msub><mo>=</mo><mi>C</mi><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><mi>D</mi><msub><mi>w</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\hat{y}_t = Cx_t + Dw_t</annotation></semantics></math>. Thus,<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>y</mi><mo accent="true">̂</mo></mover><mi>t</mi></msub><annotation encoding="application/x-tex">\hat{y}_t</annotation></semantics></math> is a kind of forward model. Plugging in,</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>A</mi><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><mi>B</mi><msub><mi>u</mi><mi>t</mi></msub><mo>+</mo><msub><mi>η</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">x_{t+1} = Ax_t + Bu_t + \eta_t</annotation></semantics></math></p>
<p>becomes</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right"><msub><mi>x</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mtd><mtd columnalign="left"><mo>=</mo><mi>A</mi><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><mi>B</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>y</mi><mi>t</mi></msub><mo>−</mo><mi>C</mi><msub><mi>x</mi><mi>t</mi></msub><mo>−</mo><mi>D</mi><msub><mi>w</mi><mi>t</mi></msub><mo stretchy="false" form="postfix">)</mo><mo>+</mo><msub><mi>η</mi><mi>t</mi></msub></mtd></mtr><mtr><mtd columnalign="right"><msub><mi>x</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mtd><mtd columnalign="left"><mo>=</mo><mo stretchy="false" form="prefix">(</mo><mi>A</mi><mo>−</mo><mi>B</mi><mi>C</mi><mo stretchy="false" form="postfix">)</mo><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><mi>B</mi><msub><mi>y</mi><mi>t</mi></msub><mo>−</mo><mi>B</mi><mi>D</mi><msub><mi>w</mi><mi>t</mi></msub><mo>+</mo><msub><mi>η</mi><mi>t</mi></msub></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
x_{t+1} &amp;= Ax_t + B(y_t - Cx_t - Dw_t) + \eta_t \\
x_{t+1} &amp;= (A-BC)x_t + By_t - BDw_t + \eta_t
\end{aligned}
</annotation></semantics></math></p>
<h4 id="target-prediction-error-learning">Target Prediction Error Learning</h4>
<p>Now let <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mi>t</mi></msub><mo>=</mo><msub><mover><mi>y</mi><mo accent="true">̂</mo></mover><mi>t</mi></msub><mo>−</mo><msubsup><mi>y</mi><mi>t</mi><mo>*</mo></msubsup></mrow><annotation encoding="application/x-tex">u_t = \hat{y}_t - y^*_t</annotation></semantics></math>, the difference between predicted output and target output.</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right"><msub><mi>x</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mtd><mtd columnalign="left"><mo>=</mo><mi>A</mi><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><mi>B</mi><mo stretchy="false" form="prefix">(</mo><mi>C</mi><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><mi>D</mi><msub><mi>w</mi><mi>t</mi></msub><mo>−</mo><msubsup><mi>y</mi><mi>t</mi><mo>*</mo></msubsup><mo stretchy="false" form="postfix">)</mo><mo>+</mo><msub><mi>η</mi><mi>t</mi></msub></mtd></mtr><mtr><mtd columnalign="right"><msub><mi>x</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mtd><mtd columnalign="left"><mo>=</mo><mo stretchy="false" form="prefix">(</mo><mi>A</mi><mo>+</mo><mi>B</mi><mi>C</mi><mo stretchy="false" form="postfix">)</mo><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><mi>B</mi><mi>D</mi><msub><mi>w</mi><mi>t</mi></msub><mo>−</mo><mi>B</mi><msubsup><mi>y</mi><mi>t</mi><mo>*</mo></msubsup><mo>+</mo><msub><mi>η</mi><mi>t</mi></msub></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
x_{t+1} &amp;= Ax_t + B(Cx_t + Dw_t - y^*_t) + \eta_t \\
x_{t+1} &amp;= (A+BC)x_t + BDw_t - By^*_t + \eta_t
\end{aligned}
</annotation></semantics></math></p>
<h4 id="steady-state">Steady State</h4>
<p>If we take the output and state vectors in expectation for constant inputs <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>w</mi><annotation encoding="application/x-tex">w</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>r</mi><annotation encoding="application/x-tex">r</annotation></semantics></math>, we have</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right"><msub><mi>y</mi><mi>∞</mi></msub></mtd><mtd columnalign="left"><mo>=</mo><munder><mo>lim</mo><mrow><mi>t</mi><mo>→</mo><mi>∞</mi></mrow></munder><mstyle mathvariant="double-struck"><mi>𝔼</mi></mstyle><mrow><mo stretchy="true" form="prefix">[</mo><mi>C</mi><msub><mi>x</mi><mi>∞</mi></msub><mo>+</mo><mi>D</mi><mi>w</mi><mo stretchy="true" form="postfix">]</mo></mrow></mtd></mtr><mtr><mtd columnalign="right"><msub><mi>x</mi><mi>∞</mi></msub></mtd><mtd columnalign="left"><mo>=</mo><munder><mo>lim</mo><mrow><mi>t</mi><mo>→</mo><mi>∞</mi></mrow></munder><mstyle mathvariant="double-struck"><mi>𝔼</mi></mstyle><mrow><mo stretchy="true" form="prefix">[</mo><mi>A</mi><msub><mi>x</mi><mi>∞</mi></msub><mo>+</mo><mi>B</mi><mi>u</mi><mo stretchy="true" form="postfix">]</mo></mrow></mtd></mtr><mtr><mtd columnalign="right"></mtd><mtd columnalign="left"><mo>=</mo><mi>A</mi><msub><mi>x</mi><mi>∞</mi></msub><mo>+</mo><mi>G</mi><mi>r</mi><mo>+</mo><mi>H</mi><msub><mi>y</mi><mi>∞</mi></msub></mtd></mtr><mtr><mtd columnalign="right"></mtd><mtd columnalign="left"><mo>=</mo><mi>A</mi><msub><mi>x</mi><mi>∞</mi></msub><mo>+</mo><mi>G</mi><mi>r</mi><mo>+</mo><mi>H</mi><mi>C</mi><msub><mi>x</mi><mi>∞</mi></msub><mo>+</mo><mi>H</mi><mi>D</mi><mi>w</mi></mtd></mtr><mtr><mtd columnalign="right"><mo>−</mo><mo stretchy="false" form="prefix">(</mo><mi>A</mi><mo>+</mo><mi>H</mi><mi>C</mi><mo>−</mo><mstyle mathvariant="double-struck"><mi>𝕀</mi></mstyle><mo stretchy="false" form="postfix">)</mo><msub><mi>x</mi><mi>∞</mi></msub></mtd><mtd columnalign="left"><mo>=</mo><mi>H</mi><mi>D</mi><mi>w</mi><mo>+</mo><mi>G</mi><mi>r</mi><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
y_\infty &amp;= \lim_{t\to\infty}\mathbb{E}\left[Cx_\infty + Dw\right] \\
x_\infty &amp;= \lim_{t\to\infty}\mathbb{E}\left[Ax_\infty + Bu\right] \\
&amp;= Ax_\infty + Gr + Hy_\infty \\
&amp;= Ax_\infty + Gr + HCx_\infty + HDw \\
-(A + HC - \mathbb{I})x_\infty &amp;= HDw + Gr.
\end{aligned}
</annotation></semantics></math></p>
<p>Thus, the eigenvalues of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>+</mo><mi>H</mi><mi>C</mi></mrow><annotation encoding="application/x-tex">A + HC</annotation></semantics></math> must be less than or equal to 1 for <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>∞</mi></msub><annotation encoding="application/x-tex">x_\infty</annotation></semantics></math> to be stable in expectation.</p>
<h2 id="unsupervised-feature-extraction">Unsupervised Feature Extraction</h2>
<p>We want to determine a redundant control space from data taken during natural activity. The difficulty with this is that such a natural activity manifold may display spatial (channel-wise) correlations that are possibly physiologically separable. Thus, there are two aims which must be addressed separately:</p>
<ol type="1">
<li>Expore subjects’ ability to decorrelate descending output to the muscles which have been shown to be correlated in a natural activity dataset.
<ul>
<li>Such a structured exploration might provide support for the hypothesis that “synergies” are flexible correlations between muscles driven by task demands rather than (or in addition to) physiological structure. This needs to be done incredibly carefully to escape criticism of hard-wired synergy enthusiasts.</li>
<li>See <em>de Rugy 2012</em> for a critique of OFC and hard-wired synergies</li>
</ul></li>
<li>Use common correlated outputs to develop a family of BMI-type learning tasks as a proxy for a “novel skill”, then track motor planning of this new skill to compare with motor planning algorithms.
<ul>
<li>We might be able to get #1 for free by going after this goal if we’re careful in the setup</li>
<li>This is arguably a more impactful focus as it connects low-level motor hierarchy data (EMG) to high-level planning with a normative hypothesis.</li>
</ul></li>
</ol>
<p>Electrode data from a single trial of a single session is held in a data matrix <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math> (n_electrodes, n_samples), and we wish to find a latent weight matrix <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>W</mi><annotation encoding="application/x-tex">W</annotation></semantics></math> (n_electrodes, n_components) which reconstructs <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math> by projecting latent trajectories <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>H</mi><annotation encoding="application/x-tex">H</annotation></semantics></math> (n_components, n_samples) into electrode space:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>=</mo><mi>W</mi><mo>⋅</mo><mi>H</mi></mrow><annotation encoding="application/x-tex">
X = W\cdot{H}
</annotation></semantics></math></p>
<p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>H</mi><annotation encoding="application/x-tex">H</annotation></semantics></math> is the activity of the latent processes, and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>W</mi><annotation encoding="application/x-tex">W</annotation></semantics></math> is there mixing matrix. The columns of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>W</mi><annotation encoding="application/x-tex">W</annotation></semantics></math> are the principal vectors spanning the latent subspace in electrode space. If we have new samples, we can project these new points onto this subspace:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow></msub><mo>=</mo><msup><mi>W</mi><mi>T</mi></msup><mo>⋅</mo><msub><mi>w</mi><mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow></msub></mrow><annotation encoding="application/x-tex">
h_{new} = W^T\cdot{w_{new}}
</annotation></semantics></math></p>
<p>To justify this decomposition, we have to make some assumptions about the nature of the EMG signal, namely that the signal is linear instantaneous (each EMG sample can be instantly mapped to control space). The other assumption is that the basis <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>W</mi><annotation encoding="application/x-tex">W</annotation></semantics></math> should be orthonormal, that the columns of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>W</mi><annotation encoding="application/x-tex">W</annotation></semantics></math> are orthogonal with unity norm. This ensures that the left inverse <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>W</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><annotation encoding="application/x-tex">W^{-1}</annotation></semantics></math> is equal to the transpose <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>W</mi><mi>T</mi></msup><annotation encoding="application/x-tex">W^T</annotation></semantics></math> such that:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right"><mi>X</mi></mtd><mtd columnalign="left"><mo>=</mo><mi>W</mi><mo>⋅</mo><mi>H</mi></mtd></mtr><mtr><mtd columnalign="right"><msup><mi>W</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo>⋅</mo><mi>X</mi></mtd><mtd columnalign="left"><mo>=</mo><mi>H</mi></mtd></mtr><mtr><mtd columnalign="right"><msup><mi>W</mi><mi>T</mi></msup><mo>⋅</mo><mi>X</mi></mtd><mtd columnalign="left"><mo>=</mo><mi>H</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{align}
X &amp;= W\cdot{H} \\
W^{-1}\cdot{X} &amp;= {H} \\
W^{T}\cdot{X} &amp;= {H}
\end{align}
</annotation></semantics></math></p>
<p>See <em>Muceli 2014</em> for use of the Moore-Penrose pseudoinverse in place of the transpose when the columns of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>W</mi><annotation encoding="application/x-tex">W</annotation></semantics></math> do not form an orthonormal basis. This would be the case for NMF. Is there a factorization that produces nonnegative, orthogonal coordinates? Or is the pseudoinverse okay? I will need to test this.</p>
<p>Stated in an information theoretic way, we want to minimize the reconstruction loss <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mstyle mathvariant="script"><mi>ℒ</mi></mstyle><annotation encoding="application/x-tex">\mathcal{L}</annotation></semantics></math> for our derived encoder-decoder pair (<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>E</mi><annotation encoding="application/x-tex">E</annotation></semantics></math>,<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>D</mi><annotation encoding="application/x-tex">D</annotation></semantics></math>). We’re decoding high dimensional activity into its latent dimensions, and encoding back into the high dimensional space. :</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><munder><mo>min</mo><mrow><mi>E</mi><mo>,</mo><mi>D</mi></mrow></munder><mrow><mstyle mathvariant="script"><mi>ℒ</mi></mstyle><mrow><mo stretchy="true" form="prefix">[</mo><mi>X</mi><mo>−</mo><mi>E</mi><mi>D</mi><mi>X</mi><mo stretchy="true" form="postfix">]</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">
\min_{E,D}{\mathcal{L}\left[X - EDX\right]}
</annotation></semantics></math></p>
<p>This way, forget about orthonormality and solve for an encoder and decoder directly. That is, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mo>≠</mo><mi>D</mi></mrow><annotation encoding="application/x-tex">E\neq{D}</annotation></semantics></math> is perfectly acceptable.</p>
<p>Each row of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>D</mi><annotation encoding="application/x-tex">D</annotation></semantics></math> might be called a <strong>spatial filter</strong>, a linear combination of electrode activities into a surrogate, hopefully more intuitive space.</p>
<p>In general to find such a basis we must :</p>
<ul>
<li>Extract “natural activity manifold” from freeform data</li>
<li>Use features of this natural subspace to derive control mapping
<ul>
<li>Linear iid features:
<ul>
<li>PCA</li>
<li>dPCA</li>
<li>NMF</li>
<li>ICA</li>
</ul></li>
<li>Linear time-dependent features:
<ul>
<li>SSA</li>
<li>LDS model / PGM</li>
</ul></li>
<li>Nonlinear
<ul>
<li>autoencoders</li>
<li>networks</li>
</ul></li>
</ul></li>
</ul>
<p>The behaviors present in our calibration dataset are crucial, as they determine the spatial correlations used to generate the mapping. If only complex, multi-muscle movements are present in the calibration, it will be impossible to decode subtle movements involving few muscles. Additionally, because extraction is unsupervised, it will be impossible to know how to alter the control basis directions (if we wish to do so) such that they involve single muscles or the smallest sets of muscles.</p>
<p>Ultimately, we want to find reproducible features in our data that are due to muscle coordination alone, rather than volitional movements. We want the lowest level covariance that reflects physiology rather than a task-level behavioral description (see <em>Todorov, Ghahramani 2005</em> and <em>Ingram, Wolpert 2009</em>). The idea is that if we collect data from enough tasks, we can extract the common modes of muscle activity. This is true only if we are sampling uniformly from the space of tasks. Otherwise one task, and therefore one coordination pattern, will be overrepresented.</p>
<h1 id="experiment">Experiment</h1>
<h1 id="modeling">Modeling</h1>
<h2 class="unnumbered" id="bibliography">Bibliography</h2>
<div id="refs" class="references" role="doc-bibliography">
<div id="ref-McNamee2019">
<p>1. McNamee, D. &amp; Wolpert, D. M. Internal Models in Biological Control. <em>Annual Review of Control, Robotics, and Autonomous Systems</em> <strong>2</strong>, 339–364 (2019).</p>
</div>
</div>

</div>
</div>
</body>
</html>