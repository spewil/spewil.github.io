
\documentclass[a4paper,12pt]{article}

\usepackage{fancyhdr}
\pagestyle{fancy}
\lhead{\small{Spencer Wilson}}
\chead{\small{SWC PhD Application}}
\rhead{\small{\today}}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

\begin{document}

HOW DO(ES THE BRAIN) (WE) CONTROL THE BRAIN ?? 

neural\_manifolds brief 
two paras with some math describing the theory 

para 1 -- general overview of the concept linking structure to dynamics 
para 2 -- the problem of formalizing nonlinear systems into a graph-like structure for analysis 
	of motifs, in some sort of matrix form
	perhaps the problem is our graph formalism
		does there exist another data structure that lends itself to this analysis 
	what information do we have?
		which cells are connected to which other cells and their strengths (time-dependent, slow)
		the potential of each cell as a time series (time-dependent, fast)

this is a theoretical project 

i think that there is something that hasn't been properly looked at w.r.t. the low dimensional manifolds and control theory-- how does the structure give rise to certain topologies that can be optimally controlled? do the dynamics support these ideas?

to-do
	look at spiking data 
	perform NLDR using manifold sculpting or something else (using Keras, scikit etc)
	code FVS algorithm 

connect structure to the dynamics -- can we choose nodes, or subnetworks of importance based on their contribution to the low-dimensional manifolds on which the dynamical trajectories lie? like finding a relationship between nodes that can change the manifold or can most effectively change the dynamics on that manifold? 
	some sort of dimensionality reduction and reconstruction from fewer nodes..? 
	can we score each node depending on its perturbative power...? 

read the brockett paper \cite{Brockett2014}
read structural control paper \cite{Zanudo2017}

\begin{align}
	dX_i/dt &= F_i(X_i,X_{I_i},t) \\ 
	dS_j/dt &= G_j(t)
\end{align}

if $N_s$ is the number of source nodes, then 

\begin{align}
&= \\ 
\end{align}

read the FVS papers \cite{Betzel} \cite{Whalen2016}

have to figure out how to write down the system in state space without sacrificing too much of the neural dynamics, but keeping things as smooth as possible... lots of balls in the air, captain. 

	there are certain system types (bilinear, etc) that lend themselves to the FVS analysis. we have to figure out what kinds of system allow for reasonable neural dynamics, and then what constraints are imposed on the manifolds of such systems. 


essentially:
	write down a simple model of neuron threshold dynamics 
	choose your favorite network model (degree distro, etc)
	find a connection between 
		the weight matrix of this graph 
		the threshold dynamics of individual neurons (are they all identical, is something missing in their dynamics (i.e. neurotransmitter effects?))
		the low-dimensional dynamics that come out

some people are using PCA to work out the relevant dimensions of the time series, then adding some of the nonlinearity back using the 4th order correlations (Barahona)

how do subspace manifolds inform the controllability of the system? 

% architecture => info processing => manifolds => identification of motifs, modules, and connections

When asked what I do, I invariably say: ``I'm an engineer.'' This is a statement of how I think about myself in the world; I think of interactions in terms of models, systems, and control signals. As such, I am eager to think about the inner workings of the brain using the framework of control theory. The brain is a complex network system dancing with feedback interactions. The brain is ``controlled'' by incoming environment signals while it is ``controlling'' itself through internal circuits. By altering the substrate on which this processing takes place, can we effectively control brain activity? I hypothesize that the relationship between the structure of biological neural networks and the geometry of neural dynamical manifolds is vital to answer this question. The interplay between structure and dynamics is my favorite ``hard question'' in neuroscience, and one that holds great promise for controlling brain function. 

% GOALS / IMPACT OF THE PROBLEM 

Understanding how the anatomical architecture of the brain is implicated in the transformation of high-dimensional input signals onto low-dimensional geometries is key to understanding how we can control neural dynamics and how the brain controls itself. Thinking in control theoretic terms, can I identify structural subnetworks of neurons that contribute to the low-dimensional manifolds on which neural dynamical trajectories lie? Can I find neurons that can warp the manifold, the dynamics on that manifold, or both? Such a control theory for the brain will allow us to influence learning and decision making ``online,'' with targeted inputs. We can develop treatments in neuropathology, and we can think formally about psychopathology in a mathematical framework, where the manifold concept has been theorized for over a decade \cite{Gallese2003}. In developing a geometric neural control theory, I foresee potential applications to a range of neuroscientific interests including vision, sleep, and motor function. 

% PRIOR LIT / FUTURE STUDY  

Indeed, interest has piqued recently concerning the phenomena of low-dimensional neural activity and its manifolds related to certain tasks \cite{Gao2015, Gao2017, Sadtler2014}. Similarly, there has been recent work applying the theories of optimal control to neuroscience \cite{Schiff2012}. However, my specific interest lies in understanding how stimuli that emanate externally from the environment and recurrently from the brain itself can be cast as control signals which modulate the (fast) dynamical processes of the brain as well as its (slow) learning processes. I aim to leverage the rapidly expanding cache of experimental data, both dynamic and connectomic, to understand how they are linked. By applying control theoretic techniques alongside tools from complex networks, I will work to relate the structure of neural circuitry to its macroscopic dynamics. 

This project will require me to expand my knowledge of control theory beyond canonical nonlinear systems encountered in engineering to the relatively young concepts found in geometric nonlinear control theory \cite{Brockett2014}. To connect this theory to data, I plan to work with state-of-the-art nonlinear dimensionality reduction techniques to analyze neural dynamics. Finally, I will connect these findings to the structure of networks by contributing to the recent graph theoretic problems posed to explore nonlinear network systems \cite{Tang2017, Zanudo2016}. 

% HOW TO DO IT 

I propose experiments \textit{in vivo} and \textit{in silico} simultaneously. In the former, we will use an optical brain-machine-interface to train a mouse on a simple task wherein chosen cells control neurofeedback. We would then image the cortical region implicated in the task and infer its structural connectivity using information theoretic techniques as well as its dynamical manifold through nonlinear dimensionality reduction \cite{Orlandi2014, Gashler2008}. Using metrics comprising graph theoretical measures from nonlinear systems theory combined with the geometry of dynamical manifolds, we predict which cells contribute most to the control cells' activities. This is the key theoretical step in this work. Finally, we ablate the predicted ``driver'' cells to effect a drop in performance as well as measure the compensation, if any, by the circuit to the change in structure. 

\textit{In silico}, we would generate neural data using a random graph model of a neural network according to our desired parameters. In this way, we can perform similar experiments numerically while forming hypotheses about how the macroscopic graph structure changes the control theoretic and geometric properties of the learned task. Rather than extracting structural information from imaging data, we design artificial neural networks to encode trajectories on nonlinear manifolds, and perform the same analyses for a range of parameters and generative models. With numerical experimentation we can support theoretical ideas between neural network structure and dynamics, develop new generative models, and compare our simulated hypotheses to experiments.   

% WHY ME? WHY SWC? 

I am fortunate to have established a strong foundation in control theory and experimental study during my undergraduate at MIT, a grounding in differential geometry and topology in my MPhil at Cambridge, and a focus on the linear control theory of random network systems during my MSc at Imperial. As an engineer eager to apply my skill set to difficult problems in neuroscience, I am seeking an environment where I can think creatively with others from different backgrounds. As an institution designed for multidisciplinary effort, the SWC is the ideal place for me to contribute my unique vision and vocabulary to the collaborative effort of answering questions not unlike the one outlined here. 

% CONCLUDE 

My goal is to both theoretically formalize and experimentally support links between the structure of biological neural networks and dynamical manifolds upon which neural dynamics are hypothesized to occur. This leaves many questions: what should the geometry of these dynamical manifolds be? How does the environment shape these manifolds during development, and how does this influence relate to geometric control theory? Using this control theoretic perspective, can we determine the true ``driver'' nodes or edges in biological neural networks?

Through such research, we can discover how the brain learns and stores those learned behaviors, and, perhaps, how we might  alter neural dynamics. Graph theory, control theory, and geometry (perhaps a mathematical engineer's most prized tools), taken together with carefully designed \textit{in vivo} and \textit{in silico} experiments, will provide the foundations for this exciting new framework for understanding how the environment and the brain work in tandem as a complex control system. 


\newpage
\bibliographystyle{unsrt}
\bibliography{bibliography}

\end{document}